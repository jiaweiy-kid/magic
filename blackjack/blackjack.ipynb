{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "21点环境\n",
    "=======\n",
    "state: [玩家手牌列表], 庄家明牌\n",
    "action: {叫牌(0)，停牌(1)}\n",
    "reward: 胜利 1，失败 -1，平局 0\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BasePolicy:\n",
    "    \"\"\"策略基类\n",
    "    \"\"\"\n",
    "\n",
    "    def act(self, obs):\n",
    "        raise NotImplementedError('Policy.act Not Implemented')\n",
    "\n",
    "\n",
    "class DealerPolicy(BasePolicy):\n",
    "    \"\"\"庄家策略\n",
    "\n",
    "    手牌小于17要牌，否则停止\n",
    "    \"\"\"\n",
    "\n",
    "    def act(self, obs):\n",
    "        if obs < 17:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_point(traj):\n",
    "    \"\"\"工具函数，计算一个牌列表的最大点数\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    traj : list of int\n",
    "        牌列表\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    point : int\n",
    "        最大点数\n",
    "    \"\"\"\n",
    "    s = 0\n",
    "    num_ace = 0\n",
    "    for card in traj:\n",
    "        if card == 1:\n",
    "            num_ace += 1\n",
    "            s += 11\n",
    "        else:\n",
    "            s += card\n",
    "\n",
    "    while s > 21 and num_ace > 0:\n",
    "        s -= 10\n",
    "        num_ace -= 1\n",
    "        \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackJack:\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # 动作空间\n",
    "        # 0: 要牌\n",
    "        # 1: 停止\n",
    "        self.action_space = (0, 1)\n",
    "\n",
    "        # 游戏状态:\n",
    "        # 0 玩家抽卡阶段，玩家停止抽卡时进入下一阶段\n",
    "        # 1 庄家抽卡阶段\n",
    "        # 2 结算阶段\n",
    "        self.state = 0\n",
    "\n",
    "        # 玩家与庄家的卡\n",
    "        self.player_trajectory = []\n",
    "        self.dealer_trajectory = []\n",
    "\n",
    "        # 庄家策略\n",
    "        self.dealer_policy = DealerPolicy()\n",
    "\n",
    "    def reset(self):\n",
    "        # 给每人发两张卡\n",
    "        self.player_trajectory = []\n",
    "        self.player_trajectory.append(self._get_card())\n",
    "        self.player_trajectory.append(self._get_card())\n",
    "        self.dealer_trajectory = []\n",
    "        self.dealer_trajectory.append(self._get_card())\n",
    "        self.dealer_trajectory.append(self._get_card())\n",
    "\n",
    "        self.state = 0\n",
    "\n",
    "        return self._get_obs()\n",
    "\n",
    "    def step(self, action):\n",
    "        if action == 0:  # 玩家抽卡\n",
    "            assert self.state == 0, '只能在 0 状态抽卡'\n",
    "\n",
    "            # 抽卡\n",
    "            self.player_trajectory.append(self._get_card())\n",
    "\n",
    "            # 检测是否爆牌\n",
    "            if self._is_blast(self.player_trajectory):\n",
    "                return self._get_obs(), -1, True, {}\n",
    "\n",
    "            return self._get_obs(), 0, False, {}\n",
    "\n",
    "        elif action == 1:  # 玩家停止要牌\n",
    "            # 进入庄家决策阶段\n",
    "            self.state += 1\n",
    "\n",
    "            # 获取庄家观测\n",
    "            dealer_obs = max_point(self.dealer_trajectory)\n",
    "            # 庄家决策\n",
    "            action = self.dealer_policy.act(dealer_obs)\n",
    "            while action == 0:\n",
    "                # 庄家抽牌\n",
    "                self.dealer_trajectory.append(self._get_card())\n",
    "                # 计算当前点数之和\n",
    "                dealer_obs = max_point(self.dealer_trajectory)\n",
    "                # 爆牌检测，如果庄家爆牌，玩家得到1的回报\n",
    "                if self._is_blast(self.dealer_trajectory):\n",
    "                    return self._get_obs(), 1, True, {}\n",
    "                # 如果没有爆牌，根据当前点数计算新的动作\n",
    "                action = self.dealer_policy.act(dealer_obs)\n",
    "\n",
    "            # 庄家停止要牌，开始结算\n",
    "            self.state += 1\n",
    "            player_point = max_point(self.player_trajectory)\n",
    "            dealer_point = max_point(self.dealer_trajectory)\n",
    "            # 比较点数，计算回报\n",
    "            if player_point > dealer_point:\n",
    "                reward = 1\n",
    "            elif player_point == dealer_point:\n",
    "                reward = 0\n",
    "            else:\n",
    "                reward = -1\n",
    "            return self._get_obs(), reward, True, {}\n",
    "\n",
    "        else:\n",
    "            raise ValueError('非法动作')\n",
    "\n",
    "    def _get_card(self):\n",
    "        \"\"\"抽卡\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            抽到的卡(1-10)\n",
    "        \"\"\"\n",
    "        card = np.random.randint(1, 14)  # 原来有14张牌,但10,J,Q,K都表示为10\n",
    "        card = min(card, 10)\n",
    "        return card\n",
    "\n",
    "    def _get_obs(self):\n",
    "        \"\"\"获取观测\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Cards : list of int\n",
    "            手牌列表\n",
    "        Dealer's card 1 : int\n",
    "            庄家的第一张牌\n",
    "        \"\"\"\n",
    "        return (self.player_trajectory.copy(), self.dealer_trajectory[0])\n",
    "\n",
    "    def _is_blast(self, traj):\n",
    "        \"\"\"检测是否爆牌\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        traj : list of int\n",
    "            牌列表\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        blast : bool\n",
    "            如果爆牌返回 True，否则 False\n",
    "        \"\"\"\n",
    "        return max_point(traj) > 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "起始观测 = ([3, 10], 3)\n",
      "玩家 = [3, 10], 庄家 = [3, 9]\n",
      "动作 = 0\n",
      "观测 = ([3, 10, 3], 3), 奖励 = 0, 是否结束 = False\n",
      "玩家 = [3, 10, 3], 庄家 = [3, 9]\n",
      "动作 = 1\n",
      "观测 = ([3, 10, 3], 3), 奖励 = 1, 是否结束 = True\n"
     ]
    }
   ],
   "source": [
    "#进行一轮测试(随机策略)\n",
    "env = BlackJack()  # 定义环境\n",
    "observation = env.reset()  # 获得初始观测\n",
    "print(\"起始观测 = {}\".format(observation))\n",
    "while True:\n",
    "    print(\"玩家 = {}, 庄家 = {}\".format(env.player_trajectory, env.dealer_trajectory))\n",
    "    action = np.random.choice(len(env.action_space))\n",
    "    print('动作 = {}'.format(action))\n",
    "    observation, reward, done, _ = env.step(action)\n",
    "    print(\"观测 = {}, 奖励 = {}, 是否结束 = {}\".format(observation, reward, done))\n",
    "    if done == True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtostate(observation):\n",
    "    return (sum(observation[0]), observation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_monte_carlo(policy, env, episode_num = 500000):\n",
    "    q = np.zeros_like(policy)  # 动作价值函数\n",
    "    c = np.zeros_like(policy)  # 动作数目统计\n",
    "    for _ in range(episode_num):\n",
    "        observation = env.reset()\n",
    "        state_actions = []\n",
    "        while True:\n",
    "            state = obtostate(observation)\n",
    "            action = np.random.choice(len(env.action_space), p = policy[state])\n",
    "            state_actions.append((state, action))\n",
    "            observation, reward, done, _ = env.step(action)\n",
    "            if done == True:\n",
    "                break\n",
    "        g = reward  # 因回报只和最终结果有关，故不需要统计过程中reward的值\n",
    "        for state, action in state_actions:  # 蒙特卡罗法估计\n",
    "            c[state][action] += 1\n",
    "            q[state][action] += (g - q[state][action]) / c[state][action]\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#训练\n",
    "policy = np.zeros([22, 11, 2]) # 22:玩家可能的总点数和，11:庄家可能的总点数和(前面的22，11为状态数)，2:动作数\n",
    "policy[20:, :, 1] = 1 # 当玩家点数大于20时，不可能再拿牌\n",
    "policy[:20, :, 0] = 1 # 当玩家点数小于20时，必定再要牌\n",
    "q = evaluate_monte_carlo(policy, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.array(q)\n",
    "v = (q * policy).sum(axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "起始观测 = ([9, 7], 9)\n",
      "玩家 = [9, 7], 庄家 = [9, 5, 10]\n",
      "动作 = 1\n",
      "观测 = ([9, 7], 9), 奖励 = 1, 是否结束 = True\n"
     ]
    }
   ],
   "source": [
    "#用该原始策略所获得的价值函数进行测试\n",
    "observation = env.reset()  # 获得初始观测\n",
    "print(\"起始观测 = {}\".format(observation))\n",
    "while True:\n",
    "    state = obtostate(observation)\n",
    "    action = np.argmax(q[state])\n",
    "    observation, reward, done, _ = env.step(action)\n",
    "    print(\"玩家 = {}, 庄家 = {}\".format(env.player_trajectory, env.dealer_trajectory))\n",
    "    print('动作 = {}'.format(action))\n",
    "    print(\"观测 = {}, 奖励 = {}, 是否结束 = {}\".format(observation, reward, done))\n",
    "    if done == True:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_with_exploring_start(env, episode_num=500000):\n",
    "    policy = np.zeros([22, 11, 2])\n",
    "    policy[:, :, 1] = 1\n",
    "    q = np.zeros_like(policy)\n",
    "    c = np.zeros_like(policy)\n",
    "    for _ in range(episode_num):\n",
    "        state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def monte_carlo_soft(env, episode_num = 500000, epsilon = 0.05):\n",
    "    policy = np.ones([22, 11, 2]) * 0.5\n",
    "    q = np.zeros_like(policy)\n",
    "    c = np.zeros_like(policy)\n",
    "    for _ in range(episode_num):\n",
    "        observation = env.reset()\n",
    "        state_actions = []\n",
    "        while True:\n",
    "            state = obtostate(observation)\n",
    "            action = np.random.choice(len(env.action_space), p = policy[state])\n",
    "            state_actions.append((state, action))\n",
    "            observation, reward, done, _ = env.step(action)\n",
    "            if done == True:\n",
    "                break\n",
    "        g = reward\n",
    "        for state, action in state_actions:\n",
    "            c[state][action] += 1\n",
    "            q[state][action] += (g - q[state][action]) / c[state][action]\n",
    "            a = np.argmax(q[state])  # 柔性策略\n",
    "            policy[state] = epsilon / len(env.action_space)\n",
    "            policy[state][a] += 1. - epsilon\n",
    "    return q, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, policy = monte_carlo_soft(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用该策略的获胜率 = 0.4063\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "episode = 50000\n",
    "success_time = 0\n",
    "for _ in range(episode):\n",
    "    observation = env.reset()  # 获得初始观测\n",
    "#     print(\"起始观测 = {}\".format(observation))\n",
    "    while True:\n",
    "        state = obtostate(observation)\n",
    "        action = np.argmax(policy[state])\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "#         print(\"玩家 = {}, 庄家 = {}\".format(env.player_trajectory, env.dealer_trajectory))\n",
    "#         print('动作 = {}'.format(action))\n",
    "#         print(\"观测 = {}, 奖励 = {}, 是否结束 = {}\".format(observation, reward, done))\n",
    "        if done == True:\n",
    "            break\n",
    "    if reward == 1:\n",
    "        success_time += 1\n",
    "print(\"使用该策略的获胜率 = {}\".format(success_time / episode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class playerAgent:\n",
    "    def __init__(self, env, polic):\n",
    "        env = BlackJack()\n",
    "        policy = np.ones([22, 11, 2]) * 0.5\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
